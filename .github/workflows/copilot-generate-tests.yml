name: Copilot Agent - Generate Tests

on:
  issues:
    types: [opened, assigned]
  workflow_dispatch:
    inputs:
      branch:
        description: Branch to analyze and generate tests for
        required: true
      changed_files:
        description: Newline-separated list of changed Java source files
        required: false
      frameworks_hint:
        description: Optional hint of frameworks found (JUnit5, SpringBootTest, Mockito, Cucumber, Testcontainers)
        required: false

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  generate-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Parse branch from issue or use input
        id: parse_branch
        uses: actions/github-script@v7
        with:
          script: |
            let branch = '${{ inputs.branch }}';
            let changedFiles = '${{ inputs.changed_files }}';
            let frameworksHint = '${{ inputs.frameworks_hint }}';
            
            // If triggered by issue event, parse from issue body
            if (context.eventName === 'issues') {
              // Only process if assigned to copilot
              const assignees = context.payload.issue.assignees.map(a => a.login);
              if (!assignees.includes('copilot')) {
                console.log('Issue not assigned to @copilot, skipping workflow');
                core.setOutput('should_skip', 'true');
                return;
              }
              
              const issueBody = context.payload.issue.body || '';
              
              // Parse branch from issue body (format: "Branch: <branch-name>")
              const branchMatch = issueBody.match(/Branch:\s*([^\n\s]+)/);
              if (branchMatch) {
                branch = branchMatch[1];
              } else {
                console.log('Could not parse branch from issue body, defaulting to main');
                branch = 'main';
              }
              
              // Parse changed files from issue body
              const filesSection = issueBody.match(/Changed files:[\s\S]*?(?=\n\n|$)/);
              if (filesSection) {
                const fileMatches = filesSection[0].matchAll(/- (.+\.java)/g);
                changedFiles = Array.from(fileMatches, m => m[1]).join('\n');
              }
            }
            
            console.log(`Branch: ${branch}`);
            console.log(`Changed files: ${changedFiles}`);
            console.log(`Frameworks hint: ${frameworksHint}`);
            
            core.setOutput('branch', branch);
            core.setOutput('changed_files', changedFiles);
            core.setOutput('frameworks_hint', frameworksHint);
            core.setOutput('should_skip', 'false');

      - name: Skip if not for copilot
        if: steps.parse_branch.outputs.should_skip == 'true'
        run: |
          echo "Skipping workflow - issue not assigned to @copilot"
          exit 0

      - name: Checkout target branch
        if: steps.parse_branch.outputs.should_skip == 'false'
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.parse_branch.outputs.branch }}

      - name: Setup Java
        if: steps.parse_branch.outputs.should_skip == 'false'
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: '21'

      - name: Analyze project dependencies and frameworks
        if: steps.parse_branch.outputs.should_skip == 'false'
        id: analyze
        run: |
          echo "Detecting existing test frameworks in src/test..."
          frameworks=""
          if grep -R "org.junit.jupiter" src/test 2>/dev/null; then frameworks="${frameworks}JUnit5, "; fi
          if grep -R "@SpringBootTest" src/test 2>/dev/null; then frameworks="${frameworks}SpringBootTest, "; fi
          if grep -R "org.mockito" src/test 2>/dev/null; then frameworks="${frameworks}Mockito, "; fi
          if grep -R "io.cucumber" src/test 2>/dev/null; then frameworks="${frameworks}Cucumber, "; fi
          if grep -R "org.testcontainers" src/test 2>/dev/null; then frameworks="${frameworks}Testcontainers, "; fi
          frameworks="${frameworks%, }"
          echo "frameworks=${frameworks}" >> $GITHUB_OUTPUT
          
          echo "Analyzing pom.xml dependencies..."
          dependencies=""
          
          # Check for Spring Web
          if grep -q "spring-boot-starter-web" pom.xml; then 
            dependencies="${dependencies}spring-web, "
          fi
          
          # Check for Spring Data JPA
          if grep -q "spring-boot-starter-data-jpa" pom.xml; then 
            dependencies="${dependencies}spring-data-jpa, "
          fi
          
          # Check for Spring Data JDBC
          if grep -q "spring-boot-starter-data-jdbc" pom.xml; then 
            dependencies="${dependencies}spring-data-jdbc, "
          fi
          
          # Check for Spring Data Redis
          if grep -q "spring-boot-starter-data-redis" pom.xml; then 
            dependencies="${dependencies}spring-data-redis, "
          fi
          
          # Check for Spring Data MongoDB
          if grep -q "spring-boot-starter-data-mongodb" pom.xml; then 
            dependencies="${dependencies}spring-data-mongodb, "
          fi
          
          # Check for Spring Kafka
          if grep -q "spring-kafka" pom.xml; then 
            dependencies="${dependencies}spring-kafka, "
          fi
          
          # Check for Spring AMQP/RabbitMQ
          if grep -q "spring-boot-starter-amqp" pom.xml; then 
            dependencies="${dependencies}spring-amqp, "
          fi
          
          # Check for WebFlux
          if grep -q "spring-boot-starter-webflux" pom.xml; then 
            dependencies="${dependencies}spring-webflux, "
          fi
          
          dependencies="${dependencies%, }"
          echo "dependencies=${dependencies}" >> $GITHUB_OUTPUT
          
          echo "Detected dependencies: ${dependencies}"

      - name: Create or update issue to trigger Copilot Coding Agent
        if: steps.parse_branch.outputs.should_skip == 'false'
        id: create_issue
        uses: actions/github-script@v7
        with:
          script: |
            const branch = '${{ steps.parse_branch.outputs.branch }}';
            const changedFiles = `${{ steps.parse_branch.outputs.changed_files }}`;
            const frameworksHint = '${{ steps.parse_branch.outputs.frameworks_hint }}' || '${{ steps.analyze.outputs.frameworks }}';
            const dependencies = '${{ steps.analyze.outputs.dependencies }}';
            const issueTitle = `Generate tests for branch ${branch} (paymentprocessor)`;
            
            const issueBody = `Please analyze the paymentprocessor repo on branch '${branch}' and generate tests for changed Java sources.

            **Context:**
            - Branch: ${branch}
            - Changed files:
            ${changedFiles || 'Analyze all recent changes on branch'}
            - Existing test frameworks detected: ${frameworksHint || 'None detected'}
            - Dependencies found in pom.xml: ${dependencies || 'None detected'}

            **CRITICAL - Branch Context:**
            - This workflow is running on branch '${branch}'
            - ALL code changes in this branch MUST be included in generated tests
            - Copilot MUST create PR branch FROM '${branch}', NOT from 'main'
            - This ensures all fixes and changes from the source branch are preserved

            **Requirements:**
            1. **Validate dependencies first**: Inspect pom.xml to confirm which Spring/testing dependencies are present before generating tests.
            2. **Use existing frameworks**: Prefer test frameworks already in use: ${frameworksHint || 'JUnit 5, Mockito, Spring Boot Test (defaults)'}.
            3. **Generate appropriate test types**:
               - **Unit tests**: Always generate for changed classes using JUnit 5 + Mockito for mocking.
               - **Integration tests**: 
                 - **MANDATORY**: MUST use Testcontainers for all integration tests
                 - **DO NOT** use TestRestTemplate, @SpringBootTest without containers, or in-memory databases
                 - **REQUIRED**: Use real containers (PostgreSQL, MySQL, MongoDB, Redis, Kafka, RabbitMQ, etc.)
                 - Testcontainers configuration is already available in src/test/resources/application-test.yml
                 - Example: Use @Testcontainers, @Container PostgreSQLContainer for database integration tests
                 - **MUST** update src/test/resources/init.db (or equivalent schema file) with test data needed for new tests
               - **BDD tests**: 
                 - **MANDATORY**: MUST use Testcontainers for all BDD/Cucumber scenarios
                 - **DO NOT** use TestRestTemplate or mock services in BDD tests
                 - BDD tests MUST run against real containers to validate end-to-end behavior
                 - Use Cucumber with Testcontainers integration
                 - **MUST** update src/test/resources/init.db with test data for BDD scenarios
            4. **Edge case coverage**: Include comprehensive test scenarios covering:
               - Null/empty inputs and boundary conditions
               - Error conditions and exception handling
               - Concurrent access scenarios (if applicable)
               - Invalid state transitions
               - Resource exhaustion and timeout scenarios
               - Security edge cases (unauthorized access, invalid tokens, etc.)
            5. **CRITICAL - Coverage Verification (MANDATORY - NEVER SKIP)**:
               - **MUST** verify coverage after generating ALL tests
               - **MUST** run \`./mvnw clean test jacoco:report\` to generate coverage report
               - **MUST** check JaCoCo XML report at target/site/jacoco/jacoco.xml for actual coverage percentages
               - **REQUIRED THRESHOLDS** (coverage MUST meet or exceed these):
                 - Minimum 80% line coverage for ALL changed source files
                 - Minimum 80% branch coverage for ALL changed source files
               - **IF coverage is below thresholds**: Generate additional tests to meet requirements
               - **NEVER** skip coverage verification - this is MANDATORY before finalizing PR
               - **MUST** include coverage report summary in PR description with actual percentages
               - Do NOT generate redundant tests that test the same path/scenario
               - Focus on meaningful tests that validate actual business logic and edge cases
            6. **Test quality and necessity**:
               - Do NOT create tests for:
                 - Simple getters/setters without logic
                 - Constructors with only field assignments
                 - DTOs/POJOs with no behavior
                 - Auto-generated code (Lombok @Data, etc.)
               - DO create tests for:
                 - Business logic and calculations
                 - Validation logic
                 - State management and workflows
                 - External integrations and API calls
                 - Data transformations and mappings
                 - Security-sensitive operations
            7. **Default fallbacks** (if no test frameworks detected):
               - JUnit 5 for unit tests
               - Mockito for mocking
               - Spring Boot Test (@SpringBootTest) for integration tests
               - Testcontainers for container-based integration tests
               - Cucumber JVM for BDD (optional, add if valuable)
            8. **Keep changes minimal**: Focus only on test code; do not refactor production code unless absolutely required for testability.
            9. **Verify coverage**: After generating tests, validate that the coverage thresholds (80% line and branch) are met for all changed source files.
            10. **CRITICAL - TestContainers for Integration & BDD Tests (STRICTLY ENFORCED)**:
                - **MANDATORY**: ALL integration and BDD tests MUST ONLY use Testcontainers - NO EXCEPTIONS
                - **PROHIBITED**: NEVER use TestRestTemplate, @SpringBootTest without containers, H2/in-memory databases, embedded services, or mock HTTP servers
                - **Container Selection**: 
                  - Use REAL containers matching production (PostgreSQL, MySQL, MongoDB, Redis, Kafka, RabbitMQ, etc.)
                  - IF no official Testcontainer exists for an external service: Create a MOCK Testcontainer using GenericContainer with the service's Docker image
                  - Example mock container: \`GenericContainer.withImage("custom-service:latest").withExposedPorts(8080)\`
                - **Every Integration/BDD Test MUST**:
                  - Have @Testcontainers annotation
                  - Declare @Container fields for ALL external dependencies
                  - Use @DynamicPropertySource or @ServiceConnection for configuration
                  - Execute against real containerized services ONLY
                - **Configuration**: Testcontainers config is in src/test/resources/application-test.yml or TestContainersConfig.java
                - **Test Data Management**:
                  - **MUST** update src/test/resources/init.db (or schema.sql/data.sql) with SQL INSERT statements for test data
                  - Include realistic test data that covers edge cases and scenarios in your tests
                  - Ensure referential integrity (foreign keys, constraints)
                  - Use meaningful test data names (e.g., "Test Customer 1", "CUST001")
                - **BDD/Cucumber with Testcontainers**:
                  - Use @Testcontainers and @Container in step definitions
                  - Share container instances across scenarios using singleton pattern
                  - Reset database state between scenarios using init.db or @BeforeEach cleanup
                - **Example patterns to follow**:
                  \`\`\`java
                  @Testcontainers
                  @SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
                  class MyIntegrationTest {
                      @Container
                      static PostgreSQLContainer<?> postgres = new PostgreSQLContainer<>("postgres:15-alpine")
                          .withDatabaseName("testdb")
                          .withInitScript("init.db");
                      
                      @DynamicPropertySource
                      static void configureProperties(DynamicPropertyRegistry registry) {
                          registry.add("spring.datasource.url", postgres::getJdbcUrl);
                          registry.add("spring.datasource.username", postgres::getUsername);
                          registry.add("spring.datasource.password", postgres::getPassword);
                      }
                  }
                  \`\`\`
            11. **CRITICAL - Test Execution, Coverage & Auto-Fix**:
                - **STEP 1 - Run ALL Tests**: Execute \`./mvnw clean test\` for ENTIRE test suite (unit + integration + BDD)
                  - **NOT** just the newly created tests - run ALL tests in the project
                  - This ensures newly generated tests don't break existing tests
                  - ALL test types MUST execute: unit tests, integration tests, BDD/Cucumber tests
                - **STEP 2 - Generate Coverage Report**: Run \`./mvnw jacoco:report\`
                  - Parse target/site/jacoco/jacoco.xml for coverage metrics
                  - Verify EVERY changed source file meets 80% line AND branch coverage thresholds
                  - IF below threshold: Generate additional tests and re-run coverage
                - **STEP 3 - Add Coverage to PR**:
                  - Include coverage summary in PR description showing:
                    - Overall coverage percentage
                    - Per-file coverage for all changed files
                    - Comparison with threshold (80%)
                  - Attach jacoco.xml or coverage report as PR comment
                - **IF ANY tests fail** (new or existing): Analyze the error messages and fix the issues automatically
                - Common issues to check and fix:
                  - **Missing @Mock annotations**: Ensure ALL service dependencies are mocked (e.g., PaymentAuditService, FraudService, etc.)
                  - **Missing imports**: Add required import statements (e.g., java.time.LocalDateTime, PaymentAuditService)
                  - **Type mismatches**: Convert types as needed (e.g., double to String using String.valueOf())
                  - **NullPointerExceptions**: Verify all mocked dependencies are properly initialized
                  - **Incorrect expected values**: Ensure test assertions match actual service behavior
                  - **Existing tests failing**: Update existing test files if they're missing mocks for new dependencies
                - **Re-run ALL tests** (\`./mvnw clean test\`) after each fix until ALL tests pass
                - **DO NOT commit** until \`./mvnw test\` exits with code 0 (success) for ALL ${Math.max(54, 0)}+ tests
                - Document any fixes made in the PR description, especially fixes to existing tests
            12. **IMPORTANT - Test Attribution**: Add a clear Javadoc comment at the top of EVERY generated test file:
               \`\`\`java
               /**
                * Generated by GitHub Copilot Agent
                * Issue: #<issue-number>
                * Date: <generation-date>
                * 
                * DO NOT EDIT: This test was auto-generated by Copilot Agent.
                * Review the tests and modify as needed for your specific use case.
                */
               \`\`\`
               For Cucumber feature files, use:
               \`\`\`gherkin
               # Generated by GitHub Copilot Agent
               # Issue: #<issue-number>
               # Date: <generation-date>
               # DO NOT EDIT: This test was auto-generated. Review and modify as needed.
               \`\`\`

            #github-pull-request_copilot-coding-agent
            `;

            // Check for existing open issue
            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'copilot-agent,tests'
            });

            const existingIssue = issues.find(issue => issue.title === issueTitle);
            let issueNumber;

            if (existingIssue) {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: issueBody
              });
              console.log(`Updated existing issue #${existingIssue.number}`);
              issueNumber = existingIssue.number;
            } else {
              const { data: newIssue } = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: issueTitle,
                body: issueBody,
                labels: ['copilot-agent', 'tests']
              });
              console.log(`Created new issue #${newIssue.number}`);
              issueNumber = newIssue.number;
            }
            
            core.setOutput('issue_number', issueNumber);

      - name: Wait for Copilot Agent to create or update PR
        if: steps.parse_branch.outputs.should_skip == 'false'
        id: wait_for_pr
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = ${{ steps.create_issue.outputs.issue_number }};
            const maxAttempts = 60; // Wait up to 30 minutes (30s * 60)
            const delayMs = 30000; // 30 seconds between checks
            
            let attempt = 0;
            let prFound = false;
            let prNumber = null;
            let prBranch = null;
            
            console.log(`Waiting for Copilot Agent to respond to issue #${issueNumber}...`);
            
            while (attempt < maxAttempts && !prFound) {
              attempt++;
              console.log(`Attempt ${attempt}/${maxAttempts}...`);
              
              // Check if issue was closed by Copilot without creating a PR
              const { data: issue } = await github.rest.issues.get({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber
              });
              
              if (issue.state === 'closed') {
                console.log('Issue was closed without creating a PR. Agent may have determined no tests were needed.');
                core.setOutput('pr_created', 'false');
                core.setOutput('agent_action', 'closed_no_pr');
                return;
              }
              
              // Check for PRs created by Copilot Agent
              const { data: prs } = await github.rest.pulls.list({
                owner: context.repo.owner,
                repo: context.repo.repo,
                state: 'open',
                sort: 'created',
                direction: 'desc',
                per_page: 20
              });
              
              // Look for PR created by copilot-swe-agent that mentions this issue
              for (const pr of prs) {
                if (pr.user.login === 'copilot-swe-agent[bot]' || pr.user.type === 'Bot') {
                  const { data: timeline } = await github.rest.issues.listEventsForTimeline({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issueNumber
                  });
                  
                  // Check if this PR is linked to our issue
                  const prMentionsIssue = timeline.some(event => 
                    event.event === 'cross-referenced' && 
                    event.source?.issue?.number === pr.number
                  );
                  
                  if (prMentionsIssue || pr.body?.includes(`#${issueNumber}`)) {
                    console.log(`Found Copilot PR #${pr.number}: ${pr.title}`);
                    prFound = true;
                    prNumber = pr.number;
                    prBranch = pr.head.ref;
                    break;
                  }
                }
              }
              
              if (!prFound && attempt < maxAttempts) {
                await new Promise(resolve => setTimeout(resolve, delayMs));
              }
            }
            
            if (prFound) {
              console.log(`âœ… Copilot created PR #${prNumber} from branch ${prBranch}`);
              core.setOutput('pr_created', 'true');
              core.setOutput('pr_number', prNumber);
              core.setOutput('pr_branch', prBranch);
              core.setOutput('agent_action', 'created_pr');
            } else {
              console.log('â±ï¸ Timeout: No PR created within the waiting period.');
              core.setOutput('pr_created', 'false');
              core.setOutput('agent_action', 'timeout');
            }

      - name: Close issue with summary
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = ${{ steps.create_issue.outputs.issue_number }};
            const prCreated = '${{ steps.wait_for_pr.outputs.pr_created }}' === 'true';
            const agentAction = '${{ steps.wait_for_pr.outputs.agent_action }}';
            const prNumber = '${{ steps.wait_for_pr.outputs.pr_number }}';
            const prBranch = '${{ steps.wait_for_pr.outputs.pr_branch }}';
            
            let summaryComment = '## ðŸ¤– Copilot Agent Workflow Summary\n\n';
            
            if (agentAction === 'created_pr') {
              summaryComment += `âœ… **Status**: PR Created Successfully\n\n`;
              summaryComment += `- **PR**: #${prNumber}\n`;
              summaryComment += `- **Branch**: \`${prBranch}\`\n`;
              summaryComment += `- **Next Steps**:\n`;
              summaryComment += `  1. CI pipeline will run on the PR branch\n`;
              summaryComment += `  2. Review the generated tests in PR #${prNumber}\n`;
              summaryComment += `  3. Merge the PR if tests are satisfactory\n\n`;
              summaryComment += `Closing this issue as the tests have been generated.`;
            } else if (agentAction === 'closed_no_pr') {
              summaryComment += `â„¹ï¸ **Status**: No PR Created\n\n`;
              summaryComment += `The Copilot Agent closed this issue without creating a PR.\n`;
              summaryComment += `Possible reasons:\n`;
              summaryComment += `- No test generation was needed\n`;
              summaryComment += `- Tests already exist for the changed files\n`;
              summaryComment += `- Agent determined the changes don't require new tests\n`;
            } else if (agentAction === 'timeout') {
              summaryComment += `â±ï¸ **Status**: Timeout\n\n`;
              summaryComment += `The workflow timed out waiting for Copilot Agent to create a PR.\n`;
              summaryComment += `Possible reasons:\n`;
              summaryComment += `- Agent is still processing (check back later)\n`;
              summaryComment += `- Agent encountered an error\n`;
              summaryComment += `- Issue was not properly assigned to @copilot\n\n`;
              summaryComment += `**Action Required**: Check issue status and reassign to @copilot if needed.`;
            }
            
            // Add comment with summary
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: summaryComment
            });
            
            // Close issue if PR was created or if agent closed it
            if (agentAction === 'created_pr' || agentAction === 'closed_no_pr') {
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issueNumber,
                state: 'closed',
                state_reason: 'completed'
              });
              console.log(`âœ… Issue #${issueNumber} closed with summary`);
            }

      - name: Add CI status comment to PR
        if: steps.wait_for_pr.outputs.pr_created == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = '${{ steps.wait_for_pr.outputs.pr_number }}';
            
            console.log(`Adding comment to PR #${prNumber}`);
            
            // Add comment to PR explaining CI will run automatically
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body: 'ðŸ¤– Tests have been generated by Copilot Agent.\n\nâœ… CI pipeline will run automatically on each commit to verify the tests.\n\nReview the generated tests and merge when CI passes.'
            });

      - name: Post workflow summary
        if: always()
        run: |
          echo "## Workflow Completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Issue**: #${{ steps.create_issue.outputs.issue_number }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Agent Action**: ${{ steps.wait_for_pr.outputs.agent_action }}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.wait_for_pr.outputs.pr_created }}" = "true" ]; then
            echo "- **PR Created**: #${{ steps.wait_for_pr.outputs.pr_number }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Branch**: ${{ steps.wait_for_pr.outputs.pr_branch }}" >> $GITHUB_STEP_SUMMARY
            echo "- **CI**: Runs automatically on PR commits" >> $GITHUB_STEP_SUMMARY
          else
            echo "- **PR Created**: No" >> $GITHUB_STEP_SUMMARY
          fi
